{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HmHDXTyTVY_"
      },
      "source": [
        "**Required imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z55ukyJjLhDP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    callbacks,\n",
        "    utils,\n",
        "    metrics,\n",
        "    losses,\n",
        "    optimizers,\n",
        ")\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeTApw9QTnJb"
      },
      "source": [
        "Downloading CelebA dataset using kaggle API and unpacking it on local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCGg2plrTcym",
        "outputId": "22bd706c-7779-4ea2-b1d8-ddb7c685d8cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDLIQ12CL0Xw",
        "outputId": "b33ed910-0c73-4b22-e8c8-6c4c1785a1fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "celeba-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/drive/MyDrive/kaggle')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle'\n",
        "!kaggle datasets download -d jessicali9530/celeba-dataset\n",
        "os.chdir('/content')\n",
        "!cp '/content/drive/MyDrive/kaggle/celeba-dataset.zip' .\n",
        "!unzip -q 'celeba-dataset.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbIn-FhagOxc"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 64\n",
        "CHANNELS = 3\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "SEED = 42\n",
        "MAX_EPOCHS = 50\n",
        "PATIENCE = 5\n",
        "\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "Z_DIM = 50\n",
        "BETA = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOYC3yweFy86"
      },
      "outputs": [],
      "source": [
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/ML_DL/FaceGeneration/Models'\n",
        "BEST_MODEL_SAVE_PATH = '/content/drive/MyDrive/ML_DL/FaceGeneration'\n",
        "LOG_SAVE_PATH = '/content/drive/MyDrive/ML_DL/FaceGeneration'\n",
        "RECONSTRUCTION_IMAGES_SAVE_PATH = '/content/drive/MyDrive/ML_DL/FaceGeneration/Reconstructions'\n",
        "GENERATED_IMAGES_SAVE_PATH = '/content/drive/MyDrive/ML_DL/FaceGeneration/Generated'\n",
        "\n",
        "random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data generators"
      ],
      "metadata": {
        "id": "3uP4a9pWDxnF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q20i9GFQ8OYS",
        "outputId": "8a1afa07-979b-4c24-b891-62f34e7cb895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whole dataframe length: 202599\n",
            "Train dataframe length: 162770\n",
            "Validation dataframe length: 19867\n",
            "Test dataframe length: 19962\n"
          ]
        }
      ],
      "source": [
        "partition_df = pd.read_csv('/content/list_eval_partition.csv')\n",
        "partition_df['partition'] = partition_df['partition'].replace({0: 'train'})\n",
        "partition_df['partition'] = partition_df['partition'].replace({1: 'validation'})\n",
        "partition_df['partition'] = partition_df['partition'].replace({2: 'test'})\n",
        "\n",
        "train_df = partition_df[partition_df['partition'] == 'train']\n",
        "val_df = partition_df[partition_df['partition'] == 'validation']\n",
        "test_df = partition_df[partition_df['partition'] == 'test']\n",
        "\n",
        "print(f'Whole dataframe length: {len(partition_df)}')\n",
        "print(f'Train dataframe length: {len(train_df)}')\n",
        "print(f'Validation dataframe length: {len(val_df)}')\n",
        "print(f'Test dataframe length: {len(test_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEdrmfdIBD2T"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCUQ01LHGv2H",
        "outputId": "284b2f36-e69d-45d2-e136-756b10fe0d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 162770 validated image filenames.\n",
            "Found 19867 validated image filenames.\n",
            "Found 19962 validated image filenames.\n"
          ]
        }
      ],
      "source": [
        "train_generator = datagen.flow_from_dataframe(\n",
        "  dataframe=train_df,\n",
        "  directory='/content/img_align_celeba/img_align_celeba',\n",
        "  x_col='image_id',\n",
        "  y_col=None,\n",
        "  target_size=(IMG_SIZE, IMG_SIZE),\n",
        "  batch_size=BATCH_SIZE,\n",
        "  class_mode=None,\n",
        "  shuffle=True,\n",
        "  seed=SEED,\n",
        "  interpolation=\"bilinear\",\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_dataframe(\n",
        "  dataframe=val_df,\n",
        "  directory='/content/img_align_celeba/img_align_celeba',\n",
        "  x_col='image_id',\n",
        "  y_col=None,\n",
        "  target_size=(IMG_SIZE, IMG_SIZE),\n",
        "  batch_size=BATCH_SIZE,\n",
        "  class_mode=None,\n",
        "  shuffle=True,\n",
        "  seed=SEED,\n",
        "  interpolation=\"bilinear\",\n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_dataframe(\n",
        "  dataframe=test_df,\n",
        "  directory='/content/img_align_celeba/img_align_celeba',\n",
        "  x_col='image_id',\n",
        "  y_col=None,\n",
        "  target_size=(IMG_SIZE, IMG_SIZE),\n",
        "  batch_size=BATCH_SIZE,\n",
        "  class_mode=None,\n",
        "  shuffle=True,\n",
        "  seed=SEED,\n",
        "  interpolation=\"bilinear\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model architecture"
      ],
      "metadata": {
        "id": "gG5mT0ZCD1ph"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lwUyhU4f3HM"
      },
      "outputs": [],
      "source": [
        "class Sampling(layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBUL6YSxf9fH",
        "outputId": "bf51f53d-e714-4415-9493-9166d0f8ae75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)  [(None, 64, 64, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)           896       ['encoder_input[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 32, 32, 32)           128       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)     (None, 32, 32, 32)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)           18496     ['leaky_re_lu[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 16, 16, 64)           256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 64)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)            73856     ['leaky_re_lu_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 8, 8, 128)            512       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)            0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 256)            295168    ['leaky_re_lu_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 4, 4, 256)            1024      ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 256)            0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 4096)                 0         ['leaky_re_lu_3[0][0]']       \n",
            "                                                                                                  \n",
            " z_mean (Dense)              (None, 50)                   204850    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " z_log_var (Dense)           (None, 50)                   204850    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " sampling (Sampling)         (None, 50)                   0         ['z_mean[0][0]',              \n",
            "                                                                     'z_log_var[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 800036 (3.05 MB)\n",
            "Trainable params: 799076 (3.05 MB)\n",
            "Non-trainable params: 960 (3.75 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "encoder_input = layers.Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS), name=\"encoder_input\")\n",
        "\n",
        "x = layers.Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(    encoder_input)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(256, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "z_mean = layers.Dense(Z_DIM, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(Z_DIM, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "encoder = models.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGHpWrLlgTsN",
        "outputId": "8c88abf2-9986-4cb6-d339-8432239139c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 50)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              208896    \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 4096)              16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 4096)              0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 8, 8, 256)         590080    \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 8, 8, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 16, 16, 128)       295040    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2D  (None, 32, 32, 64)        73792     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 32, 32, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2D  (None, 64, 64, 32)        18464     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 64, 64, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2D  (None, 64, 64, 3)         867       \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1205443 (4.60 MB)\n",
            "Trainable params: 1196291 (4.56 MB)\n",
            "Non-trainable params: 9152 (35.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "decoder_input = layers.Input(shape=(Z_DIM,), name=\"decoder_input\")\n",
        "\n",
        "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Reshape(shape_before_flattening)(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(256, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "decoder_output = layers.Conv2DTranspose(3, kernel_size=3, strides=1, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "decoder = models.Model(decoder_input, decoder_output)\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnRCHu7bgdwc"
      },
      "outputs": [],
      "source": [
        "class VAE(models.Model):\n",
        "  def __init__(self, encoder, decoder, **kwargs):\n",
        "    super(VAE, self).__init__(**kwargs)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "    self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n",
        "    self.reconstruction_loss_tracker = metrics.Mean(name=\"reconstruction_loss\")\n",
        "    self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [\n",
        "      self.total_loss_tracker,\n",
        "      self.reconstruction_loss_tracker,\n",
        "      self.kl_loss_tracker,\n",
        "    ]\n",
        "\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var, z = encoder(inputs)\n",
        "    reconstruction = decoder(z)\n",
        "    return z_mean, z_log_var, reconstruction\n",
        "\n",
        "  def train_step(self, data):\n",
        "    with tf.GradientTape() as tape:\n",
        "      z_mean, z_log_var, reconstruction = self(data)\n",
        "\n",
        "      reconstruction_loss =  BETA * tf.reduce_mean(\n",
        "        losses.binary_crossentropy(\n",
        "          data, reconstruction, axis=(1, 2, 3)\n",
        "        )\n",
        "      )\n",
        "\n",
        "      kl_loss = tf.reduce_mean(\n",
        "        tf.reduce_sum(-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)), axis=1)\n",
        "        )\n",
        "\n",
        "      total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "      grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "      self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "      self.total_loss_tracker.update_state(total_loss)\n",
        "      self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "      self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "    return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "  def test_step(self, data):\n",
        "    if isinstance(data, tuple):\n",
        "      data = data[0]\n",
        "\n",
        "    z_mean, z_log_var, reconstruction = self(data)\n",
        "\n",
        "    reconstruction_loss =  BETA * tf.reduce_mean(\n",
        "        losses.binary_crossentropy(\n",
        "          data, reconstruction, axis=(1, 2, 3)\n",
        "        )\n",
        "      )\n",
        "\n",
        "    kl_loss = tf.reduce_mean(\n",
        "        tf.reduce_sum(-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)), axis=1)\n",
        "        )\n",
        "\n",
        "    total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "    return {\n",
        "      \"loss\": total_loss,\n",
        "      \"reconstruction_loss\": reconstruction_loss,\n",
        "      \"kl_loss\": kl_loss,\n",
        "    }\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    config.update({\n",
        "      'encoder': self.encoder.get_config(),\n",
        "      'decoder': self.decoder.get_config(),\n",
        "      'total_loss_tracker': self.total_loss_tracker.get_config(),\n",
        "      'reconstruction_loss_tracker': self.reconstruction_loss_tracker.get_config(),\n",
        "      'kl_loss_tracker': self.kl_loss_tracker.get_config(),\n",
        "    })\n",
        "    return config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    encoder = models.Sequential.from_config(config.pop('encoder'))\n",
        "    decoder = models.Sequential.from_config(config.pop('decoder'))\n",
        "\n",
        "    return cls(encoder=encoder, decoder=decoder, **config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRSBRmdsgmXu"
      },
      "outputs": [],
      "source": [
        "vae = VAE(encoder, decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training"
      ],
      "metadata": {
        "id": "NuOFOxrKD60z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageGeneratorCallback(callbacks.Callback):\n",
        "  def __init__(self, vae, filepath):\n",
        "    super().__init__()\n",
        "    self.vae = vae\n",
        "    self.filepath = filepath\n",
        "\n",
        "    self.samples = np.random.normal(size=(25, Z_DIM))\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    self.vae = self.model\n",
        "    images = self.vae.decoder.predict(self.samples, verbose=0)\n",
        "    filename = f\"{self.filepath}/image_generated_epoch_{epoch}.png\"\n",
        "    self._plot_images(images, filename, epoch)\n",
        "\n",
        "  def _plot_images(self, images, filename, epoch):\n",
        "    fig, axs = plt.subplots(5, 5, figsize=(15, 15))\n",
        "    plt.suptitle(f'Generated images - epoch {epoch}', fontsize=20, fontweight='bold')\n",
        "\n",
        "    for i in range(5):\n",
        "      for j in range(5):\n",
        "        axs[i, j].imshow(images[i*5+j])\n",
        "        axs[i, j].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.9)\n",
        "    plt.savefig(f\"{self.filepath}/image_generated_epoch_{epoch}.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "class ImageReconstructorCallback(callbacks.Callback):\n",
        "  def __init__(self, vae, filepath):\n",
        "    super().__init__()\n",
        "    self.vae = vae\n",
        "    self.filepath = filepath\n",
        "\n",
        "    self.original_images = []\n",
        "\n",
        "    while len(self.original_images) < 15:\n",
        "      self.original_images.append(next(test_generator)[0])\n",
        "\n",
        "    self.original_images = np.stack(self.original_images, axis=0)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    self.vae = self.model\n",
        "    reconstructed_images = self.vae.predict(self.original_images, verbose=0)[2]\n",
        "    filename = f\"{self.filepath}/image_reconstructed_epoch_{epoch}.png\"\n",
        "    self._plot_images(reconstructed_images, filename, epoch)\n",
        "\n",
        "  def _plot_images(self, reconstructed_images, filename, epoch):\n",
        "    fig, axs = plt.subplots(5, 6, figsize=(15, 15))\n",
        "    plt.suptitle(f'Reconstructed images - epoch {epoch}', fontsize=20, fontweight='bold')\n",
        "\n",
        "    for i in range(5):\n",
        "      for j in range(3):\n",
        "        axs[i, j*2].imshow(self.original_images[i*3+j])\n",
        "        axs[i, j*2].set_title('Original Image')\n",
        "        axs[i, j*2].axis('off')\n",
        "\n",
        "        axs[i, j*2 + 1].imshow(reconstructed_images[i*3+j])\n",
        "        axs[i, j*2 + 1].set_title('Reconstructed Image')\n",
        "        axs[i, j*2 + 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.9)\n",
        "    plt.savefig(f\"{self.filepath}/image_reconstructed_epoch_{epoch}.png\")\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "id": "RZD7z6in-XSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55nXwdOegn51"
      },
      "outputs": [],
      "source": [
        "eary_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)\n",
        "checkpoint = callbacks.ModelCheckpoint(f'{MODEL_SAVE_PATH}/VAE_' + '{epoch:03d}.tf', verbose=1, monitor='val_loss',save_best_only=False, mode='auto', save_format='tf')\n",
        "best_model_save = callbacks.ModelCheckpoint(f'{BEST_MODEL_SAVE_PATH}/best_model.tf', save_best_only=True, monitor='val_loss', mode='min', save_format='tf')\n",
        "csv_logger = callbacks.CSVLogger(f'{LOG_SAVE_PATH}/training_log.csv', append=True, separator=';')\n",
        "\n",
        "image_generator = ImageGeneratorCallback(vae, GENERATED_IMAGES_SAVE_PATH)\n",
        "image_reconstructor = ImageReconstructorCallback(vae, RECONSTRUCTION_IMAGES_SAVE_PATH)\n",
        "\n",
        "callbacks_list = [checkpoint,\n",
        "                  best_model_save,\n",
        "                  eary_stopping,\n",
        "                  csv_logger,\n",
        "                  image_generator,\n",
        "                  image_reconstructor\n",
        "                 ]\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "vae.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEDthvwFg1ur",
        "outputId": "8657ed37-2afb-41b7-fe30-a2d8c194ab02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5688.4341 - reconstruction_loss: 5628.5454 - kl_loss: 59.8906\n",
            "Epoch 1: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_001.tf\n",
            "636/636 [==============================] - 242s 364ms/step - total_loss: 5688.4341 - reconstruction_loss: 5628.5454 - kl_loss: 59.8906 - val_loss: 5371.4575 - val_reconstruction_loss: 5294.9053 - val_kl_loss: 76.5521\n",
            "Epoch 2/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5326.8457 - reconstruction_loss: 5248.3779 - kl_loss: 78.4677\n",
            "Epoch 2: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_002.tf\n",
            "636/636 [==============================] - 213s 335ms/step - total_loss: 5326.8457 - reconstruction_loss: 5248.3779 - kl_loss: 78.4677 - val_loss: 5389.0171 - val_reconstruction_loss: 5308.1494 - val_kl_loss: 80.8676\n",
            "Epoch 3/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5276.5923 - reconstruction_loss: 5195.6562 - kl_loss: 80.9405\n",
            "Epoch 3: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_003.tf\n",
            "636/636 [==============================] - 216s 339ms/step - total_loss: 5276.5923 - reconstruction_loss: 5195.6562 - kl_loss: 80.9405 - val_loss: 5387.7656 - val_reconstruction_loss: 5306.9814 - val_kl_loss: 80.7843\n",
            "Epoch 4/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5231.6914 - reconstruction_loss: 5148.1016 - kl_loss: 83.5933\n",
            "Epoch 4: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_004.tf\n",
            "636/636 [==============================] - 217s 341ms/step - total_loss: 5231.6914 - reconstruction_loss: 5148.1016 - kl_loss: 83.5933 - val_loss: 5201.7754 - val_reconstruction_loss: 5116.3047 - val_kl_loss: 85.4705\n",
            "Epoch 5/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5205.5840 - reconstruction_loss: 5120.4492 - kl_loss: 85.1370\n",
            "Epoch 5: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_005.tf\n",
            "636/636 [==============================] - 213s 336ms/step - total_loss: 5205.5840 - reconstruction_loss: 5120.4492 - kl_loss: 85.1370 - val_loss: 5230.7495 - val_reconstruction_loss: 5146.2744 - val_kl_loss: 84.4752\n",
            "Epoch 6/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5192.3076 - reconstruction_loss: 5106.6294 - kl_loss: 85.6822\n",
            "Epoch 6: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_006.tf\n",
            "636/636 [==============================] - 213s 335ms/step - total_loss: 5192.3076 - reconstruction_loss: 5106.6294 - kl_loss: 85.6822 - val_loss: 5154.8418 - val_reconstruction_loss: 5070.0996 - val_kl_loss: 84.7422\n",
            "Epoch 7/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5184.0098 - reconstruction_loss: 5098.3540 - kl_loss: 85.6509\n",
            "Epoch 7: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_007.tf\n",
            "636/636 [==============================] - 213s 335ms/step - total_loss: 5184.0098 - reconstruction_loss: 5098.3540 - kl_loss: 85.6509 - val_loss: 5181.2183 - val_reconstruction_loss: 5096.0396 - val_kl_loss: 85.1788\n",
            "Epoch 8/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5177.7036 - reconstruction_loss: 5092.3096 - kl_loss: 85.3929\n",
            "Epoch 8: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_008.tf\n",
            "636/636 [==============================] - 215s 337ms/step - total_loss: 5177.7036 - reconstruction_loss: 5092.3096 - kl_loss: 85.3929 - val_loss: 5148.2803 - val_reconstruction_loss: 5064.9609 - val_kl_loss: 83.3192\n",
            "Epoch 9/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5173.0698 - reconstruction_loss: 5088.0366 - kl_loss: 85.0319\n",
            "Epoch 9: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_009.tf\n",
            "636/636 [==============================] - 217s 341ms/step - total_loss: 5173.0698 - reconstruction_loss: 5088.0366 - kl_loss: 85.0319 - val_loss: 5268.6382 - val_reconstruction_loss: 5183.8203 - val_kl_loss: 84.8178\n",
            "Epoch 10/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5169.5181 - reconstruction_loss: 5084.8560 - kl_loss: 84.6607\n",
            "Epoch 10: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_010.tf\n",
            "636/636 [==============================] - 214s 337ms/step - total_loss: 5169.5181 - reconstruction_loss: 5084.8560 - kl_loss: 84.6607 - val_loss: 5220.9937 - val_reconstruction_loss: 5135.9561 - val_kl_loss: 85.0376\n",
            "Epoch 11/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5165.9038 - reconstruction_loss: 5081.6309 - kl_loss: 84.2753\n",
            "Epoch 11: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_011.tf\n",
            "636/636 [==============================] - 220s 345ms/step - total_loss: 5165.9038 - reconstruction_loss: 5081.6309 - kl_loss: 84.2753 - val_loss: 5106.9746 - val_reconstruction_loss: 5022.0796 - val_kl_loss: 84.8951\n",
            "Epoch 12/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5163.3462 - reconstruction_loss: 5079.3784 - kl_loss: 83.9695\n",
            "Epoch 12: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_012.tf\n",
            "636/636 [==============================] - 212s 333ms/step - total_loss: 5163.3462 - reconstruction_loss: 5079.3784 - kl_loss: 83.9695 - val_loss: 5227.4976 - val_reconstruction_loss: 5143.9341 - val_kl_loss: 83.5635\n",
            "Epoch 13/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5160.9448 - reconstruction_loss: 5077.3179 - kl_loss: 83.6247\n",
            "Epoch 13: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_013.tf\n",
            "636/636 [==============================] - 214s 336ms/step - total_loss: 5160.9448 - reconstruction_loss: 5077.3179 - kl_loss: 83.6247 - val_loss: 5139.7959 - val_reconstruction_loss: 5056.6870 - val_kl_loss: 83.1088\n",
            "Epoch 14/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5158.7974 - reconstruction_loss: 5075.4688 - kl_loss: 83.3322\n",
            "Epoch 14: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_014.tf\n",
            "636/636 [==============================] - 220s 346ms/step - total_loss: 5158.7974 - reconstruction_loss: 5075.4688 - kl_loss: 83.3322 - val_loss: 5098.0093 - val_reconstruction_loss: 5015.6689 - val_kl_loss: 82.3401\n",
            "Epoch 15/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5156.9277 - reconstruction_loss: 5073.7964 - kl_loss: 83.1306\n",
            "Epoch 15: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_015.tf\n",
            "636/636 [==============================] - 239s 376ms/step - total_loss: 5156.9277 - reconstruction_loss: 5073.7964 - kl_loss: 83.1306 - val_loss: 5233.0376 - val_reconstruction_loss: 5151.6187 - val_kl_loss: 81.4190\n",
            "Epoch 16/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5155.1177 - reconstruction_loss: 5072.2339 - kl_loss: 82.8856\n",
            "Epoch 16: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_016.tf\n",
            "636/636 [==============================] - 234s 368ms/step - total_loss: 5155.1177 - reconstruction_loss: 5072.2339 - kl_loss: 82.8856 - val_loss: 5283.8145 - val_reconstruction_loss: 5201.7734 - val_kl_loss: 82.0409\n",
            "Epoch 17/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5153.5420 - reconstruction_loss: 5070.8818 - kl_loss: 82.6687\n",
            "Epoch 17: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_017.tf\n",
            "636/636 [==============================] - 216s 339ms/step - total_loss: 5153.5420 - reconstruction_loss: 5070.8818 - kl_loss: 82.6687 - val_loss: 5144.3628 - val_reconstruction_loss: 5061.4219 - val_kl_loss: 82.9409\n",
            "Epoch 18/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5152.1240 - reconstruction_loss: 5069.6665 - kl_loss: 82.4550\n",
            "Epoch 18: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_018.tf\n",
            "636/636 [==============================] - 212s 333ms/step - total_loss: 5152.1240 - reconstruction_loss: 5069.6665 - kl_loss: 82.4550 - val_loss: 5213.4590 - val_reconstruction_loss: 5132.0200 - val_kl_loss: 81.4389\n",
            "Epoch 19/50\n",
            "636/636 [==============================] - ETA: 0s - total_loss: 5150.7822 - reconstruction_loss: 5068.5107 - kl_loss: 82.2742\n",
            "Epoch 19: saving model to /content/drive/MyDrive/ML_DL/FaceGeneration/Models/VAE_019.tf\n"
          ]
        }
      ],
      "source": [
        "vae.fit(\n",
        "  train_generator,\n",
        "  validation_data=val_generator,\n",
        "  epochs=MAX_EPOCHS,\n",
        "  shuffle=True,\n",
        "  callbacks=callbacks_list\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yS7OB0zAx0sE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}